{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\n\\ntraining_set = tf.contrib.learn.datasets.base.load_csv_with_header(\\n    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32)\\n\\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(\\n    x={\"x\": np.array(training_set.data)},\\n    y=np.array(training_set.target),\\n    num_epochs=None,\\n    shuffle=True)\\n\\nclassifier.train(input_fn=train_input_fn, steps=2000)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.estimatorにおける入力関数の作成方法を学ぶ\n",
    "# 序盤は説明なのでコメントばかり。後半に実際のコードがある。\n",
    "\n",
    "# input_fnは、特徴量データとターゲットデータをtrain,evaluate,predict関数に渡すことために使われる。\n",
    "# tf.estimator Quickstart tutorialでは、以下の例になっていた。\n",
    "# (classifier,trainでinput_fnが使われている)\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING, target_dtype=np.int, features_dtype=np.float32)\n",
    "\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(training_set.data)},\n",
    "    y=np.array(training_set.target),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "classifier.train(input_fn=train_input_fn, steps=2000)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef my_input_fn():\\n    # Preprocess your data here...\\n\\n    # ...then return 1) a mapping of feature columns to Tensors with\\n    # the corresponding feature data, and 2) a Tensor containing labels\\n    return feature_cols, labels\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自作の入力関数を作る場合の基本構成はfeature_colsとlabelsを返すこと。\n",
    "# fearuter_cols : keyとvalueが結びついた辞書\n",
    "# labels : label値が格納されているテンソル.正解データと思えば多分Ok.\n",
    "\n",
    "\"\"\"\n",
    "def my_input_fn():\n",
    "    # Preprocess your data here...\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pandas as pd\\n# pandas input_fn.\\nmy_input_fn = tf.estimator.inputs.pandas_input_fn(\\n    x=pd.DataFrame({\"x\": x_data}),\\n    y=pd.Series(y_data),\\n    ...)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpyやpandasの使用も可能。形式をコンバートしてくれるような関数が用意されている。\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "# numpy input_fn.\n",
    "my_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_data)},\n",
    "    y=np.array(y_data),\n",
    "    ...)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "# pandas input_fn.\n",
    "my_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=pd.DataFrame({\"x\": x_data}),\n",
    "    y=pd.Series(y_data),\n",
    "    ...)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[[0, 6, 0, 0, 0]\\n [0, 0, 0, 0, 0]\\n [0, 0, 0, 0, 0.5]]\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# スパースなデータに対しては、SparseTensorを使うと良い。\n",
    "# 以下の3つを引数に与えれば使える。\n",
    "# dense_shape: 各次元の要素数\n",
    "# indices: 非ゼロ値の入っているindex\n",
    "# values: 1次元のテンソル。indicesに対応した値が入っている。\n",
    "# 以下のようにSparseTensorを生成できる。denseでの表記も確認のため記載。\n",
    "# SparseTensorの詳細は以下\n",
    "# https://www.tensorflow.org/api_docs/python/tf/SparseTensor\n",
    "\n",
    "\"\"\"\n",
    "sparse_tensor = tf.SparseTensor(indices=[[0,1], [2,4]],\n",
    "                                values=[6, 0.5],\n",
    "                                dense_shape=[3, 5])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "[[0, 6, 0, 0, 0]\n",
    " [0, 0, 0, 0, 0]\n",
    " [0, 0, 0, 0, 0.5]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nclassifier.evaluate(input_fn=lambda: my_input_fn(test_set), steps=2000)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自分のモデルにinput_fn データを渡すには、引数input_fnに与えれば良い\n",
    "# 注意点としては、input_fnには返り値を与えるのではなく、あくまでも関数オブジェクトを渡すこと。\n",
    "\"\"\"\n",
    "classifier.train(input_fn=my_input_fn, steps=2000)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "# こっちはエラー\n",
    "classifier.train(input_fn=my_input_fn(training_set), steps=2000)\n",
    "\"\"\"\n",
    "\n",
    "# もし、入力関数をパラメタライズしたいなら、\n",
    "# 方法1.ラッパー関数を作ってしまう。\n",
    "\"\"\"\n",
    "def my_input_fn(data_set):\n",
    "  ...\n",
    "\n",
    "def my_input_fn_training_set():\n",
    "  return my_input_fn(training_set)\n",
    "\n",
    "classifier.train(input_fn=my_input_fn_training_set, steps=2000)\n",
    "\"\"\"\n",
    "# 方法2.functools.partialを使って関数オブジェクト化してしまう。\n",
    "\"\"\"\n",
    "classifier.train(\n",
    "    input_fn=functools.partial(my_input_fn, data_set=training_set),\n",
    "    steps=2000)\n",
    "\"\"\"\n",
    "\n",
    "# 方法3. lambdaを使ってラップする\n",
    "\"\"\"\n",
    "classifier.train(input_fn=lambda: my_input_fn(training_set), steps=2000)\n",
    "\"\"\"\n",
    "\n",
    "# この方法(方法3限定?)はtrainだけではなく、evaluate、predictにも使えるのでよく覚えておく。\n",
    "# (つまり、入力関数をパラメタライズしておくと、方法1のように(?)input_fn_train,input_fn_test,input_fn_predictといった複数の入力関数を用意する必要がなくなる)\n",
    "\"\"\"\n",
    "classifier.evaluate(input_fn=lambda: my_input_fn(test_set), steps=2000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport numpy as np\\n\\ndef get_input_fn_from_numpy(data_set, num_epochs=None, shuffle=True):\\n  return tf.estimator.inputs.numpy_input_fn(\\n      x={...},\\n      y=np.array(...),\\n      num_epochs=num_epochs,\\n      shuffle=shuffle)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力関数input_fnを作るにあたっては、tf.estimator.inputにある関数が便利。\n",
    "# num_epochsやshuffleも制御できることも利点。\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "def get_input_fn_from_pandas(data_set, num_epochs=None, shuffle=True):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=pdDataFrame(...),\n",
    "      y=pd.Series(...),\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "def get_input_fn_from_numpy(data_set, num_epochs=None, shuffle=True):\n",
    "  return tf.estimator.inputs.numpy_input_fn(\n",
    "      x={...},\n",
    "      y=np.array(...),\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################\n",
    "# ここから実践コード\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各種インポートを行い、詳細なログ出力用にlogging vervosityをINFOに設定\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データセットのカラム名を定義し、CSVファイルを読み込む\n",
    "# また、あとで使うために特徴量で使用するカラム名と\n",
    "# ラベルで使用するカラム名を分けておく。\n",
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "            \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\"\n",
    "\n",
    "training_set = pd.read_csv(\"boston_train.csv\", skipinitialspace=True,\n",
    "                           skiprows=1, names=COLUMNS)\n",
    "test_set = pd.read_csv(\"boston_test.csv\", skipinitialspace=True,\n",
    "                       skiprows=1, names=COLUMNS)\n",
    "prediction_set = pd.read_csv(\"boston_predict.csv\", skipinitialspace=True,\n",
    "                             skiprows=1, names=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習のために、FeatureColumnを作る。\n",
    "# 連続値を取り扱うのでreal_valued_column()を使う?\n",
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='crim', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='zn', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='indus', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='nox', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='rm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dis', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='tax', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='ptratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_every_n_hours': 10000, '_save_summary_steps': 100, '_log_step_count_steps': 100, '_model_dir': '/tmp/boston_model', '_tf_random_seed': 1, '_keep_checkpoint_max': 5, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None}\n"
     ]
    }
   ],
   "source": [
    "# DNN回帰をモデルとしてインスタンス化\n",
    "# 隠れ層のノード数(2レイヤとも10ノード)を定義し、feature_columnsを与える。\n",
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,\n",
    "                                      hidden_units=[10, 10],\n",
    "                                      model_dir=\"/tmp/boston_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# regressor(回帰モデル?)に入力データを渡すための関数を定義\n",
    "# input_fnを返す関数(wrapper)を定義することでdata_setごとにinput_fnを作れる。\n",
    "# つまり、training_setに対するinput_fn、test_setに対するinput_fn・・・のように。\n",
    "# num_epochsについては、繰り返しの回数であって、evaluateやpredictの際には1を指定する。\n",
    "# それ以外の場合(training)の場合は学習回数?に相当する?\n",
    "# shuffleについては、学習時にTrue、評価・推定時にはFalse\n",
    "def get_input_fn(data_set, num_epochs=None, shuffle=True):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "      y = pd.Series(data_set[LABEL].values),\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boston_model\\model.ckpt-5000\n",
      "INFO:tensorflow:Saving checkpoints for 5001 into /tmp/boston_model\\model.ckpt.\n",
      "INFO:tensorflow:step = 5001, loss = 1848.8\n",
      "INFO:tensorflow:global_step/sec: 500.759\n",
      "INFO:tensorflow:step = 5101, loss = 4534.5 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.36\n",
      "INFO:tensorflow:step = 5201, loss = 7335.77 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.416\n",
      "INFO:tensorflow:step = 5301, loss = 4541.39 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.941\n",
      "INFO:tensorflow:step = 5401, loss = 4580.51 (0.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 502.364\n",
      "INFO:tensorflow:step = 5501, loss = 4986.07 (0.199 sec)\n",
      "INFO:tensorflow:global_step/sec: 599.959\n",
      "INFO:tensorflow:step = 5601, loss = 5215.17 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 517.803\n",
      "INFO:tensorflow:step = 5701, loss = 2699.61 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 572.867\n",
      "INFO:tensorflow:step = 5801, loss = 3716.96 (0.175 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.449\n",
      "INFO:tensorflow:step = 5901, loss = 3697.66 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.394\n",
      "INFO:tensorflow:step = 6001, loss = 7117.89 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.294\n",
      "INFO:tensorflow:step = 6101, loss = 5245.78 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.39\n",
      "INFO:tensorflow:step = 6201, loss = 1660.96 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.824\n",
      "INFO:tensorflow:step = 6301, loss = 5447.18 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.376\n",
      "INFO:tensorflow:step = 6401, loss = 2322.14 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 557.447\n",
      "INFO:tensorflow:step = 6501, loss = 4135.2 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.9\n",
      "INFO:tensorflow:step = 6601, loss = 5650.79 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.254\n",
      "INFO:tensorflow:step = 6701, loss = 2545.78 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 559.362\n",
      "INFO:tensorflow:step = 6801, loss = 2455.8 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 546.783\n",
      "INFO:tensorflow:step = 6901, loss = 5564.9 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 569.385\n",
      "INFO:tensorflow:step = 7001, loss = 1764.07 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.643\n",
      "INFO:tensorflow:step = 7101, loss = 4869.26 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 523.163\n",
      "INFO:tensorflow:step = 7201, loss = 4153.53 (0.193 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.102\n",
      "INFO:tensorflow:step = 7301, loss = 2704.12 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 589.448\n",
      "INFO:tensorflow:step = 7401, loss = 3170.07 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 512.816\n",
      "INFO:tensorflow:step = 7501, loss = 4693.57 (0.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.108\n",
      "INFO:tensorflow:step = 7601, loss = 5618.43 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 562.06\n",
      "INFO:tensorflow:step = 7701, loss = 4305.4 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 547.836\n",
      "INFO:tensorflow:step = 7801, loss = 2735.74 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.843\n",
      "INFO:tensorflow:step = 7901, loss = 4363.64 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.204\n",
      "INFO:tensorflow:step = 8001, loss = 2765.35 (0.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 536.203\n",
      "INFO:tensorflow:step = 8101, loss = 2778.73 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.994\n",
      "INFO:tensorflow:step = 8201, loss = 4109.41 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 578.26\n",
      "INFO:tensorflow:step = 8301, loss = 3921.78 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.389\n",
      "INFO:tensorflow:step = 8401, loss = 4594.8 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 545.604\n",
      "INFO:tensorflow:step = 8501, loss = 5546.94 (0.183 sec)\n",
      "INFO:tensorflow:global_step/sec: 552.957\n",
      "INFO:tensorflow:step = 8601, loss = 3448.0 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 586.966\n",
      "INFO:tensorflow:step = 8701, loss = 2433.46 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 544.031\n",
      "INFO:tensorflow:step = 8801, loss = 5851.26 (0.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 548.006\n",
      "INFO:tensorflow:step = 8901, loss = 3875.91 (0.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.555\n",
      "INFO:tensorflow:step = 9001, loss = 3110.93 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 564.487\n",
      "INFO:tensorflow:step = 9101, loss = 3201.36 (0.177 sec)\n",
      "INFO:tensorflow:global_step/sec: 538.773\n",
      "INFO:tensorflow:step = 9201, loss = 3156.09 (0.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 560.734\n",
      "INFO:tensorflow:step = 9301, loss = 4227.58 (0.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 539.755\n",
      "INFO:tensorflow:step = 9401, loss = 3164.59 (0.187 sec)\n",
      "INFO:tensorflow:global_step/sec: 533.274\n",
      "INFO:tensorflow:step = 9501, loss = 3856.85 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 573.131\n",
      "INFO:tensorflow:step = 9601, loss = 3016.84 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 525.934\n",
      "INFO:tensorflow:step = 9701, loss = 3017.76 (0.191 sec)\n",
      "INFO:tensorflow:global_step/sec: 577.993\n",
      "INFO:tensorflow:step = 9801, loss = 4180.91 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 558.59\n",
      "INFO:tensorflow:step = 9901, loss = 4400.5 (0.179 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/boston_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2255.24.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNRegressor at 0x270e15ef128>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習する\n",
    "regressor.train(input_fn=get_input_fn(training_set), steps=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-10-15:21:08\n",
      "INFO:tensorflow:Restoring parameters from /tmp/boston_model\\model.ckpt-10000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-10-15:21:09\n",
      "INFO:tensorflow:Saving dict for global step 10000: average_loss = 11.4846, global_step = 10000, loss = 1148.46\n"
     ]
    }
   ],
   "source": [
    "# テストデータを使って評価する\n",
    "ev = regressor.evaluate(\n",
    "    input_fn=get_input_fn(test_set, num_epochs=1, shuffle=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/boston_model\\model.ckpt-10000\n",
      "Predictions: [array([ 33.71652222], dtype=float32), array([ 17.15636635], dtype=float32), array([ 23.24656677], dtype=float32), array([ 34.67623901], dtype=float32), array([ 14.61829662], dtype=float32), array([ 18.75601768], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 推定する\n",
    "# predictはiteratorを返すのでlist化してprint\n",
    "y = regressor.predict(\n",
    "    input_fn=get_input_fn(prediction_set, num_epochs=1, shuffle=False))\n",
    "# .predict() returns an iterator of dicts; convert to a list and print\n",
    "# predictions\n",
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
